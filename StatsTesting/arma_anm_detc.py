import numpy as np
import pandas as pd
import os
from StatsTesting.base_anomaly_stats import BaseAnomalyStats
from StatsTesting.anomaly_score_stats import anomaly_score_stats
from ccbdl.storages import storages
import statsmodels.api as sm
from pmdarima import auto_arima
from sklearn import metrics
from Plotting.statmodels_anomaly_plot import testdata_plotting

class AnomalyDetection_ARMA(BaseAnomalyStats):
    
    def __init__(self, path, study_config: dict, data_config: dict): 
        
        self.path = path
        self.study_config = study_config
        self.data_config = data_config
        
        super().__init__(data_config)
        
        # For storage of results and plots    
        self.parameter_storage = storages.ParameterStorage(path)
        self.parameter_storage.write("This file is automatically generated by ccbdl.learning.base.BaseLearning")
        self.figure_storage = storages.FigureStorage(path, dpi=300, types=("png", "pdf"))

    def learning(self):
        
        # AutoARMA for finding the best order for ARMA model

        self.best_order = auto_arima(self.val_array, 
                                start_p = 1, max_p = 6, 
                                start_q = 1, max_q = 6, 
                                seasonal = False, trace = True)
    
        save_order = os.path.join(self.path, "best_order")
        self.parameter_storage.write_tab("Best_order", str(self.best_order))
        
        print ("Auto ARMA is finished. Best order is found"'\n')

    def find_threshold(self):
           
        print("\n******** Finding threshold reconstruction error of the Data ********\n")                                
        
        #Validation
        endog = np.array(self.val_array)
        
        # Define the ARMA model
        order = self.best_order.order
        model = sm.tsa.arima.ARIMA(endog = endog, exog=None, order = order)
        model_fit = model.fit()
      
        residuals = np.abs(model_fit.resid)
        
        # Finding the best possible Threshold Value for Anomaly Detection              
        best_f1_score = 0.0
        best_threshold = 0.0
        best_y = 0
        
        # Iterate over different values of y
        for y in range(1, 101):  # Adjust the range according to your requirements
            threshold = float(y * (np.mean(residuals)) + np.std(residuals))
            anomaly = pd.Series(residuals) > (threshold)
            # 1 = anomaly, 0 = normal
            preds = anomaly.map(lambda x: 1.0 if x == True else 0.0)           
            v_final_preds = np.array(preds)   
            v_ground_truth = np.array(self.val_lab_array) 
            val_f1_score = metrics.f1_score(v_ground_truth, v_final_preds)
            
            if val_f1_score > best_f1_score:
                best_f1_score = val_f1_score
                best_threshold = threshold
                best_y = y
                        
        self.threshold = best_threshold
        print("Best F1 Score from val dataset:", best_f1_score, '\n')
        print("Best Threshold from Val Data:", best_threshold, '\n')
        print("Value of 'y' for the best F1 Score:", best_y, '\n')
            
        return best_threshold
 
    def find_anomalies(self):
        
        # Testing      
        endog = np.array(self.test_array)
        order = self.best_order.order
        model = sm.tsa.arima.ARIMA(endog = endog, exog=None, order = order)
        model_fit = model.fit()
        
        residuals = np.abs(model_fit.resid)                       
      
        #Predicting Anomalies       
        anomaly = pd.Series(residuals) > (self.threshold) 
        # 1 = anomaly, 0 = normal
        preds = anomaly.map(lambda x: 1.0 if x == True else 0.0)
        self.pred_labels = np.array(preds)
        
        #Counting the no of normal and anomaly datapoints
        value_counts = preds.value_counts()
        count_zeros = value_counts[0] if 0 in value_counts else 0
        count_ones = value_counts[1] if 1 in value_counts else 0
        
        print("no of actual anomalies are:", np.sum(self.test_lab_array))
        print("no of predicted anomalies are:", count_ones,'\n' )
                                               
        # Getting the scores for anomaly detection
        anomaly_score_stats(ground_truth = self.test_lab_array, 
                            final_preds = self.pred_labels,
                            param_storage = self.parameter_storage)
        
        # Plotting the data and visualizing anomalies
        testdata_plotting(path = self.path,
                          test_data = self.test_array, 
                          test_labels = self.test_lab_array, 
                          pred_labels =self.pred_labels, 
                          figure_storage = self.figure_storage)
        
        