import numpy as np
import pandas as pd
from ccbdl.storages import storages
from StatsTesting.base_anomaly_stats import BaseAnomalyStats
from StatsTesting.anomaly_score_stats import anomaly_score_stats
from sklearn.ensemble import IsolationForest
from sklearn import metrics
from Plotting.statmodels_anomaly_plot import testdata_plotting

class AnomalyDetection_ISOFOR(BaseAnomalyStats):
        
    # def __init__(self, path, network):
    def __init__(self, path, study_config: dict, data_config: dict):    
                  
        self.path = path
        self.study_config = study_config
        self.data_config = data_config
        
        super().__init__(data_config)

        # For storage of results and plots    
        self.parameter_storage = storages.ParameterStorage(path)
        self.parameter_storage.write("This file is automatically generated by ccbdl.learning.base.BaseLearning")
        self.figure_storage = storages.FigureStorage(path, dpi=300, types=("png", "pdf"))
        
        # Reshaping the data
        self.train_array = self.train_array.reshape(-1, 1)
        self.val_array = self.val_array.reshape(-1, 1)
        self.test_array = self.test_array.reshape(-1, 1)
        
        
    def learning(self):
        
      # Creating an Isolation Forest model
      self.isolation_forest = IsolationForest(n_estimators=100, # no.of trees in the forest
                                              max_samples=256, # max no.of data points that the tree should build on 
                                              contamination='auto', # estimate of perctg of anomaly
                                              random_state=42) #   
    
      # Fitting the train data into Isolation Forest model
      self.isolation_forest.fit(self.train_array)
      

    def find_threshold(self):
           
        print("\n******** Finding threshold reconstruction error of the Data ********\n")                                
        
        # Validation (for finding the best threshold value)
        anomaly_scores_val = self.isolation_forest.decision_function(self.val_array) 
        
        # Finding the best F1 score using val dataset        
        best_f1_score = 0.0
        best_threshold = 0.0
        best_y = 0
        
        # Iterate over different values of y
        start = -0.10
        end = -0.30
        step = -0.01
        
        current_value = start
        while current_value >= end:
            # print(current_value)
            threshold_val = float(current_value)
            anomaly_val = pd.Series(anomaly_scores_val) < (threshold_val)
            preds_val = anomaly_val.map(lambda x: 1.0 if x == True else 0.0)   
            final_preds_val = np.array(preds_val)       
            ground_truth_val = self.val_lab_array 
            val_f1_score = metrics.f1_score(ground_truth_val, final_preds_val)
            
            current_value += step
            
            if val_f1_score > best_f1_score:
                best_f1_score = val_f1_score
                best_threshold = threshold_val
                best_y = current_value
        
        self.threshold = best_threshold
        print("Best F1 Score from val dataset:", best_f1_score, '\n')
        print("Best Threshold from Val Data:", best_threshold, '\n')
        print("Value of 'y' for the best F1 Score:", best_y, '\n')
                    
        return best_threshold
    
    
    def find_anomalies(self):
        
        anomaly_scores = self.isolation_forest.decision_function(self.test_array)  #Average anomaly score of X
        
        # Anomaly Detection and Performance Evaluation
        threshold_val = self.threshold
        
        print('threshold value is:', threshold_val,'\n')
                    
        anomaly = pd.Series(anomaly_scores) < (threshold_val)        
        # 1 = anomaly, 0 = normal
        preds = anomaly.map(lambda x: 1.0 if x == True else 0.0)        
        self.pred_labels = np.array(preds)
        
        #Counting the no of normal and anomaly datapoints
        value_counts = preds.value_counts()
        count_zeros = value_counts[0] if 0 in value_counts else 0
        count_ones = value_counts[1] if 1 in value_counts else 0
                      
        print("no of actual anomalies are:", np.sum(self.test_lab_array))
        print("no of predicted anomalies are:", count_ones,'\n' )
        
        # Getting the scores for anomaly detection
        anomaly_score_stats(ground_truth = self.test_lab_array, 
                            final_preds = self.pred_labels,
                            param_storage = self.parameter_storage)
        
        # Plotting the data and visualizing anomalies
        testdata_plotting(path = self.path,
                          test_data = self.test_array, 
                          test_labels = self.test_lab_array, 
                          pred_labels = self.pred_labels, 
                          figure_storage = self.figure_storage)
                        

