 # -*- coding: utf-8 -*-
"""
Created on Tue Jun 27 11:50:24 2023

@author: BhargavBade
"""

import torch
import numpy as np
import torch.nn as nn
import os
from ccbdl.utils import DEVICE
from ccbdl.storages import storages
from Data.prepare_data import prepare_data
from sklearn.metrics import roc_auc_score
from sklearn.metrics import classification_report, average_precision_score
import matplotlib.pyplot as plt
from sklearn import metrics

class AnomalyDetection():
        
    # def __init__(self, path, network):
    def __init__(self, path, study_config: dict, data_config: dict):    
                  
        self.path = path
        self.threshold = None
        self.pred_labels = None
        self.testt_dataa = None
        self.study_config = study_config
        self.data_config = data_config
               
        # get data
        train_data, test_data, val_data = prepare_data(self.data_config)

        self.train_data = train_data                     
        self.test_data = test_data
        self.val_data  = val_data
        
        # For storage of results and plots    
        self.parameter_storage = storages.ParameterStorage(path)
        self.parameter_storage.write("This file is automatically generated by ccbdl.learning.base.BaseLearning")
        self.figure_storage = storages.FigureStorage(path, dpi=300, types=("png", "pdf"))
        
        # Path to retrive the best model
        self.path_best = os.path.join(self.path,"best_state.pt")
        self.path_bestmodel =  os.path.join(self.path,"best_model.pt")
                        
    def find_threshold(self):
        
        val_labels = []
        loss_crit = nn.MSELoss(reduction = 'none')
        
        print("\n******** Finding threshold reconstruction error of the Data ********\n")                                

        # Loading the saved best model along with hidden size and weights
        self.model = torch.load(self.path_bestmodel)
        self.model.eval() 
        
        val_reconstruction_error = [] 
           
        with torch.no_grad():        
            for _, (inp, labels) in enumerate(self.val_data):                           
                # get data
                inp = inp.to(torch.float32)
                inp = inp.to(DEVICE)                        
                reconstructions = self.model(inp) 
                
                # reconstructions, mu, logvar = self.model(inp)
                
                # loss                                       
                loss = loss_crit(reconstructions, inp) 
                #----------------------------------------------------------------------
                # rec_losss =  loss_crit(reconstructions, inp)
                # kl_divergence_losss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())                
                # loss = rec_losss + kl_divergence_losss
                #------------------------------------------------------------------------------
                # val_reconstruction_error.append(loss.item()) 
                val_reconstruction_error.append(loss)
                val_labels.append(labels)
            #------------------------------------------------------------------------------------------------------ 
            v_concatenated_tensor = torch.cat(val_reconstruction_error, dim=0).to(DEVICE)  
            v_loss_array = v_concatenated_tensor.cpu().numpy()                             
            self.val_labels = torch.cat(val_labels)
            
            # Finding the best possible Threshold Value for Anomaly Detection              
            best_f1_score = 0.0
            best_threshold = 0.0
            best_y = 0
            
            # Iterate over different values of y
            for y in range(1, 101):  # Adjust the range according to your requirements
                threshold = float(y * (np.mean(v_loss_array)) + (np.std(v_loss_array)))
                v_pred_labels_tensor = (v_concatenated_tensor > threshold).to(DEVICE)
                v_ground_truth_tensor_1d = self.val_labels.view(-1)
                v_preds_tensor_1d = v_pred_labels_tensor.view(-1)
                v_ground_truth = v_ground_truth_tensor_1d.cpu().numpy()
                v_final_preds = v_preds_tensor_1d.cpu().numpy()
                val_f1_score = metrics.f1_score(v_ground_truth, v_final_preds)
                
                if val_f1_score > best_f1_score:
                    best_f1_score = val_f1_score
                    best_threshold = threshold
                    best_y = y
                            
            self.threshold = best_threshold
            print("Best F1 Score from val dataset:", best_f1_score, '\n')
            print("Best Threshold from Val Data:", best_threshold, '\n')
            print("Value of 'y' for the best F1 Score:", best_y, '\n')
            
        return best_threshold
    
#------------------------------------------------------------------------------------------------- 
#Testing Phase
 
    def find_anomalies(self):
        
        self.model.eval() 
        loss_crit_test = nn.MSELoss(reduction = 'none')  
        # loss_crit_test = nn.BCELoss(reduction = 'none')  
        
        testdata_rec = []
        test_rec_error = []                 
        test_data = []
        test_labels = []
        with torch.no_grad():
            for _, (inp,labels) in enumerate(self.test_data):                            
                # get data
                inp = inp.to(torch.float32)
                inp = inp.to(DEVICE)                 
                # network
                test_reconstructions = self.model(inp)                 
               # test_reconstructions, mu, logvar = self.model(inp)                                
                testdata_rec.append(test_reconstructions)            
                # loss   
                # test_rec_error.append(loss_test.item()) #For getting single loss value for whole batch                          
                loss_test = loss_crit_test(test_reconstructions, inp)
                # #-------------------------------------------------------------------------------------- 
                # rec_loss =  loss_crit_test(test_reconstructions, inp)
                # kl_divergence_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())                
                # loss_test = rec_loss + kl_divergence_loss
                # #--------------------------------------------------------------------------------- 
                test_rec_error.append(loss_test)                              
                test_data.append(inp)  
                test_labels.append(labels) 
            self.testdata_rec = torch.cat(testdata_rec, dim = 0).to(DEVICE)
            
            # testdata_rec_array = self.testdata_rec.cpu() 
            self.test_data_tensor = torch.cat(test_data, dim = 0)
            self.test_labels = torch.cat(test_labels)
            test_rec_error_tensor = torch.cat(test_rec_error, dim=0).to(DEVICE)                       
            threshold_val = self.threshold                                      
            anomaly = (test_rec_error_tensor > threshold_val).to(DEVICE)               
            # 1 = anomaly, 0 = normal            
            pred_labels_tensor = torch.where(anomaly, torch.tensor(1).to(DEVICE), torch.tensor(0).to(DEVICE))                         
            self.pred_labels = pred_labels_tensor
                       
        # ---------------------------------------------------------------------------------        
        #Evaluating the test data based on some metrics
        
            actual_labels_tensor = self.test_labels
            
            # Reshape the original labels tensor into a 1D array
            ground_truth_tensor_1d = actual_labels_tensor.view(-1)
            
            # Count the number of zeros and ones
            normal_count = torch.sum(ground_truth_tensor_1d == 0)
            print("no of actual normal data points are:", normal_count, '\n')
            anomaly_count = torch.sum(ground_truth_tensor_1d == 1)                                
            print("no of actual anomaly data points are:", anomaly_count,'\n' ) 
            
            ground_truth = ground_truth_tensor_1d.cpu().numpy()
                        
            # Reshape the predictions label tensor into a 1D array
            preds_tensor_1d = pred_labels_tensor.view(-1)
            
            normal_count = torch.sum(preds_tensor_1d == 0)
            print("no of predicited normal data points are:", normal_count, '\n') 
            anomaly_count = torch.sum(preds_tensor_1d == 1)                                           
            print("no of predicted anomaly data points are:", anomaly_count,'\n' ) 
            
            final_preds = preds_tensor_1d.cpu().numpy()
            
            roc_auc = roc_auc_score(ground_truth, final_preds)         
            print("AUROC Score is:", roc_auc)
            roc_str = "AUROC Score is: " + str(roc_auc)
                       
            fpr, tpr, thresholds = metrics.roc_curve(ground_truth, final_preds)          
            fig = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='roc_auc_curve')
            fig.plot()
            plt.show()                   
            report = classification_report(ground_truth, final_preds, digits=4)
            print(report,'\n')

            #Calculatimg AUPRC
            auprc = average_precision_score(ground_truth, final_preds)
            print('AUPRC Score is', auprc)
            prc_str = "AUPRC Score is: " + str(auprc)        
            
            self.parameter_storage.write_tab("Classification Report", str(report))
            self.parameter_storage.write_tab("00", str(roc_str))
            self.parameter_storage.write_tab("00", str(prc_str))
                        
        return actual_labels_tensor, pred_labels_tensor

    def testdata_plotting(self):
        
        figs = []
        names = []
    
        # Get the corresponding data, actual labels, and predicted labels
        data_tensor = self.test_data_tensor.cpu()
        rec_data_tensor = self.testdata_rec.cpu()
        actual_labels = self.test_labels.cpu()
        predicted_labels = self.pred_labels.cpu()
            
        # Convert tensors to numpy arrays
        testdata = data_tensor.numpy()
        rec_testdata = rec_data_tensor.numpy()
        testdata_labels = actual_labels.numpy()
        predicted_labels = predicted_labels.numpy()
        
        # Generate 120 random indices for plotting
        random_indices = np.random.choice(testdata.shape[0], size=120, replace=False)
                    
        # Set the number of figures and subplots per figure
        figures = 20
        subplots_per_figure = 6        
        
        # Iterate over the figures
        for f in range(figures):
            # Create a new figure
            fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(20, 15))
            fig.suptitle(f"Figure {f+1}")
            name = f"Figure {f+1}"
        
            # Iterate over the subplots within the figure
            for s, ax in enumerate(axs.flat):
                # Get the corresponding index
                idx = f * subplots_per_figure + s
        
                # Get the corresponding testdata, true labels, and predicted labels
                data = testdata[random_indices[idx]]       
                rec_data = rec_testdata[random_indices[idx]]
                true_labels = testdata_labels[random_indices[idx]]
                pred_labels = predicted_labels[random_indices[idx]]
        
                # Flatten the data, true labels, and predicted labels
                flat_data = data.flatten()
                flat_rec_data = rec_data.flatten()
                flat_true_labels = true_labels.flatten()
                flat_pred_labels = pred_labels.flatten()
        
                # Highlight the values with true label 1
                true_label_indices = np.where(flat_true_labels == 1)[0]
                true_label_values = flat_data[true_label_indices]
        
                # Highlight the values with predicted label 1
                pred_label_indices = np.where(flat_pred_labels == 1)[0]
                pred_label_values = flat_data[pred_label_indices]
        
                # Plot the subplot
                ax.plot(flat_data)
                ax.plot(flat_rec_data)
                ax.scatter(true_label_indices, true_label_values, color='red', label='true_labels', alpha=0.6)
                ax.scatter(pred_label_indices, pred_label_values, color='green', marker='x', label='pred_labels', s=100 )
                       
                # Set legend
                ax.legend(loc="best")
                                
            plt.tight_layout()
            
            figs.append(fig)                               
            names.append(os.path.join("Test", "Random_Sample_" + name)) 
            
        self.figure_storage.store_multi(figs, names, folder="", dpis=False)

    
    
        
    
        
                
                    
               